**Machine Learning Basic**

# Overfitting
## Drop-out

## Cross validation - K fold

## L1 vs L2
![image](https://user-images.githubusercontent.com/39760546/184844839-69c2977f-bc17-4ece-93c8-4028e056116e.png)

*L1 regularization forces the weights of uninformative features to be zero by substracting a small amount from the weight at each iteration and thus making the weight zero, eventually*
